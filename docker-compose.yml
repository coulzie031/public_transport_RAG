
services:
  # --- SCHEDULER: Triggers Python scripts based on time ---
  scheduler:
    image: mcuadros/ofelia:latest
    container_name: scheduler
    depends_on:
      - kafka
    volumes:
      - /var/run/docker.sock:/var/run/docker.sock:ro
    command: daemon --docker
    restart: unless-stopped

  # --- INFRASTRUCTURE: KAFKA (KRaft Mode) ---
  kafka:
    image: confluentinc/cp-kafka:latest
    container_name: kafka
    restart: unless-stopped
    ports:
      - "9092:9092"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@kafka:29093'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      CLUSTER_ID: 'MkU3OEVBNTcwNTJENDM2Qk'
      KAFKA_LISTENERS: 'PLAINTEXT://kafka:29092,CONTROLLER://kafka:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M" 
    deploy:
      resources:
        limits:
          cpus: '0.50'
          memory: 1024M

  # --- STATION PIPELINE (Manual) ---
  station-producer:
    build: .
    container_name: station-producer
    profiles: [manual]
    depends_on: [kafka]
    # FIX: Mount root + Set Working Dir + PYTHONPATH
    working_dir: /app
    volumes: 
      - .:/app
    environment:
      PYTHONPATH: /app
      KAFKA_SERVER: "kafka:29092"
      PRIM_TOKEN: ${PRIM_TOKEN}
    command: python scripts/station_producer_2.py

  app-stations-sink:
    build: .
    container_name: app-stations-sink
    depends_on: [kafka, elasticsearch]
    # FIX: Mount root + Set Working Dir + PYTHONPATH
    working_dir: /app
    volumes: 
      - .:/app
    environment:
      PYTHONPATH: /app
      KAFKA_SERVER: "kafka:29092"
      ELASTIC_SERVER: "http://elasticsearch:9200"
    command: python scripts/stations_sink.py

  # --- ALERT PIPELINE (Automatic every 5m) ---
  alert-producer:
    build: .
    container_name: alert-producer
    profiles: [manual]
    depends_on: [kafka]
    # FIX: Mount root + Set Working Dir + PYTHONPATH
    working_dir: /app
    volumes: 
      - .:/app
    environment:
      PYTHONPATH: /app
      KAFKA_SERVER: "kafka:29092"
      PRIM_TOKEN: ${PRIM_TOKEN}
    command: python scripts/distrubtion_producer.py

  app-alerts-sink:
    build: .
    container_name: app-alerts-sink
    depends_on: [kafka, elasticsearch]
    # FIX: Mount root + Set Working Dir + PYTHONPATH
    working_dir: /app
    volumes: 
      - .:/app
    environment:
      PYTHONPATH: /app
      KAFKA_SERVER: "kafka:29092"
      ELASTIC_SERVER: "http://elasticsearch:9200"
      PYTHONUNBUFFERED: "1"
      NVIDIA_API_KEY: ${NVIDIA_API_KEY}
      PRIM_TOKEN: ${PRIM_TOKEN}

    command: python scripts/distrubtion_sink.py

  # --- SEARCH: ELASTICSEARCH ---
  elasticsearch:
      image: docker.elastic.co/elasticsearch/elasticsearch:8.10.0
      container_name: elasticsearch
      ports:
        - "9200:9200"
      volumes:
        - es_data:/usr/share/elasticsearch/data 
      environment:
        - discovery.type=single-node
        - xpack.security.enabled=false
        - "ES_JAVA_OPTS=-Xms512m -Xmx512m" 
      deploy:
        resources:
          limits:
            cpus: '0.50'
            memory: 1024M

  # --- SINK: MOVING DATA FROM KAFKA TO ELASTIC (Generic) ---
  app:
    build: . 
    container_name: app-sink
    depends_on:
      - kafka
      - elasticsearch
    # FIX: Mount root + Set Working Dir + PYTHONPATH
    working_dir: /app
    volumes:
      - .:/app
    environment:
      PYTHONPATH: /app
      KAFKA_SERVER: "kafka:29092"
      ELASTIC_SERVER: "http://elasticsearch:9200"
      PYTHONUNBUFFERED: "1"
    command: python scripts/stations_sink.py
    deploy:
      resources:
        limits:
          cpus: '0.25'
          memory: 256M

volumes:
  es_data:
